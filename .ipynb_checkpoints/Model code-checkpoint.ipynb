{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import BatchNormalization,Flatten,\\\n",
    "Add,Input,Dense, Dropout, Activation, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "from augmentation_code import data_augmentation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_globals():\n",
    "    global open3D_directory\n",
    "    global dataset_name_num\n",
    "    global MIF_nodes \n",
    "    global xyz_offset\n",
    "    open3D_directory = \"C:\\open3dtools\"\n",
    "    dataset_name_num = \"06.DHFR\"\n",
    "    MIF_nodes = [23,27,21]\n",
    "    xyz_offset = [-11,-10,-9]\n",
    "set_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    path = os.path.join(r\"C:\\Users\\Linden\\GitHub\\3DQSAR\\data\\LabelledData\",dataset_name_num)\n",
    "    labels = pd.read_csv(os.path.join(path,\"pIC50.CSV\"))\n",
    "    Y = labels[\"Y\"].to_numpy()\n",
    "\n",
    "    data=[]\n",
    "\n",
    "    for entry in os.scandir(path):\n",
    "        if (entry.path.endswith(\".npy\")):\n",
    "            file = np.load(entry.path)\n",
    "            data.append(file)\n",
    "    field_1 = data[0::2]\n",
    "    field_2 = data[1::2]\n",
    "    X_1 = np.stack(field_1,0)\n",
    "    X_2 = np.stack(field_2,0)    \n",
    "    \n",
    "    return X_1, X_2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_2, Y = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Augment and extend data\n",
    "X_1, X_2, Y = data_augmentation(X_1,X_2,Y,augment_repetitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Normalise image data \n",
    "###Normalise by amax value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 25, 24, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Reshape\n",
    "X_1 = np.reshape(X_1,(X_1.shape[0],X_1.shape[1],X_1.shape[2],X_1.shape[3],1))\n",
    "X_2 = np.reshape(X_2,(X_2.shape[0],X_2.shape[1],X_2.shape[2],X_2.shape[3],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Shuffle\n",
    "permutation = np.random.RandomState(seed=42)\\\n",
    "                .permutation(X_1.shape[0])\n",
    "\n",
    "X_1 = X_1[permutation]\n",
    "X_2 = X_2[permutation]\n",
    "Y = Y[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Train test split\n",
    "train_upper = int(np.around(X_1.shape[0]*0.9,0))\n",
    "\n",
    "X_1_train = X_1[:train_upper]\n",
    "X_2_train = X_2[:train_upper]\n",
    "X_1_test = X_1[train_upper:]\n",
    "X_2_test = X_2[train_upper:]\n",
    "\n",
    "Y_train = Y[:train_upper]\n",
    "Y_test = Y[train_upper:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train validation split\n",
    "train_upper = int(np.around(X_1_train.shape[0]*0.8,0))\n",
    "X_1_val = X_1_train[train_upper:]\n",
    "X_2_val = X_2_train[train_upper:]\n",
    "X_1_train = X_1_train[:train_upper]\n",
    "X_2_train = X_2_train[:train_upper]\n",
    "\n",
    "Y_val = Y_train[train_upper:]\n",
    "Y_train = Y_train[:train_upper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN():\n",
    "    model = Sequential(name='CNN')\n",
    "    \n",
    "    # elu=Exponential Linear Unit, similar to leaky Relu\n",
    "    #perhaps normalise in layer 1 \n",
    "    \n",
    "    # Convolution Layers\n",
    "    inputs = Input(shape=(X_1_train.shape[1], X_1_train.shape[2],X_1_train.shape[3],X_1_train.shape[4]))\n",
    "    model = MaxPooling3D(pool_size=(2,2,2))(inputs)\n",
    "    model = Conv2D(32, (2, 2), strides=(1, 1), activation='elu')(model)\n",
    "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
    "    model = Conv2D(64, (2, 2), strides=(1, 1), activation='elu')(model)\n",
    "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
    "    model = Conv2D(128, (2, 2), strides=(1, 1), activation='elu')(model)\n",
    "    \n",
    "\n",
    "    output = Flatten()(model)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_headed_network():\n",
    "    X_1_CNN = build_CNN()\n",
    "    X_2_CNN = build_CNN()\n",
    "    network = Add()([X_1_CNN.output,X_2_CNN.output])\n",
    "    network = Flatten()(network)\n",
    "    network = Dense(10,activation='elu')(network)\n",
    "    network = Dense(1,activation = 'linear')(network)\n",
    "    model = Model([X_1_CNN.input, X_2_CNN.input], network)\n",
    "    optimizer = Adam(learning_rate=1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model  \n",
    "CNN = two_headed_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 30s 1s/step - loss: 1666793472.0000 - accuracy: 0.0000e+00 - val_loss: 15581303.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - ETA: 0s - loss: 10404291.0000 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "##Train \n",
    "##monitor early stopping using val_acc\n",
    "#Set min_delta to 1e-3\n",
    "monitor = EarlyStopping(monitor='val_loss',\n",
    "                        min_delta=0,\n",
    "                        patience=15,\n",
    "                        verbose=1, \n",
    "                        mode='auto',\n",
    "                        restore_best_weights=True)\n",
    "\n",
    "CNN.fit([X_1_train, X_2_train],\n",
    "        Y_train,\n",
    "        batch_size=64,\n",
    "        epochs=200, \n",
    "        validation_data=([X_1_val, X_2_val],\n",
    "                          Y_val),\n",
    "                          callbacks=[monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test model w/ best weights on validation data\n",
    "model_loss = CNN.evaluate([X_1_test,X_2_test], Y_test)\n",
    "print(f\"Model loss:{model_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
