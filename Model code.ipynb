{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_globals():\n",
    "    global open3D_directory\n",
    "    global dataset_name_num\n",
    "    global MIF_nodes \n",
    "    global xyz_offset\n",
    "    open3D_directory = \"C:\\open3dtools\"\n",
    "    dataset_name_num = \"06.DHFR\"\n",
    "    MIF_nodes = [23,27,21]\n",
    "    xyz_offset = [-11,-10,-9]\n",
    "set_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    path = os.path.join(r\"C:\\Users\\Linden\\GitHub\\3DQSAR\\data\\LabelledData\",dataset_name_num)\n",
    "    labels = pd.read_csv(os.path.join(path,\"pIC50.CSV\"))\n",
    "    Y = labels[\"Y\"].to_numpy()\n",
    "\n",
    "    data=[]\n",
    "\n",
    "    for entry in os.scandir(path):\n",
    "        if (entry.path.endswith(\".npy\")):\n",
    "            file = np.load(entry.path)\n",
    "            data.append(file)\n",
    "    field_1 = data[0::2]\n",
    "    field_2 = data[1::2]\n",
    "    X_1 = np.stack(field_1,0)\n",
    "    X_2 = np.stack(field_2,0)    \n",
    "    \n",
    "    return X_1, X_2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_2, Y = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Normalise image data \n",
    "###Normalise by amax value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Shuffle\n",
    "permutation = np.random.RandomState(seed=42)\\\n",
    "                .permutation(X_1.shape[0])\n",
    "X_1 = X_1[permutation]\n",
    "X_2 = X_2[permutation]\n",
    "Y = Y[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24, 26)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "one=np.arange(306)\n",
    "two=np.arange(306)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=np.stack([one,two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 182 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-d2ce65f4f6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 182 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "st[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([182, 154, 111, 203,  60,   9, 119, 157, 167,  33,   5, 101,  45,\n",
       "       177, 118,  46, 125, 195, 251, 143, 232, 272, 248,  25, 147, 224,\n",
       "         3,  73, 285, 109, 140, 287, 211,  42,  17, 282,  76,  90,  24,\n",
       "        57,  92,  77, 254, 116,   7, 193, 284,  78, 295, 237, 223, 291,\n",
       "        63,  82, 192, 238, 221, 104, 303, 196, 230, 271, 213, 244,  75,\n",
       "       179,  59,  93,   6, 180,  30,  22, 260,  56, 247, 114, 132, 240,\n",
       "       204, 275, 165, 220,  84,  66, 113, 168, 146,  19, 144,  79, 255,\n",
       "       124,  72,  15,  10, 164, 249,  97,  68, 233,  37,  16, 126, 152,\n",
       "       289,  67, 108,  69,  31, 181, 155, 234, 298,  18, 301,  96, 137,\n",
       "       292,  86, 258, 172, 209, 259, 294, 139, 242,  55, 173, 290, 194,\n",
       "       268, 129,  38, 202, 175, 186, 112, 256, 117, 283, 277, 288, 183,\n",
       "       185,   2, 115, 148, 184, 120, 219, 265, 127,  74,  29,  83, 253,\n",
       "       107, 158, 163, 133, 197, 225,  65, 206,  85, 222, 159,  12,  35,\n",
       "        28, 170, 142, 198, 131, 176,  51,  95, 231, 178, 229,  41,  89,\n",
       "       226, 136,  26, 299, 141, 208,   0, 274, 278, 100, 267, 103, 171,\n",
       "        98,  36,  61, 150, 246, 210, 286,  11, 302, 200, 273,  27, 228,\n",
       "         4, 122,  32, 239, 162, 218, 261, 138,  62, 215, 135, 128, 296,\n",
       "         8,  70, 280,  64,  44, 245, 156,  40, 123, 281, 216, 153,  23,\n",
       "       266, 110,  81, 236, 207, 212,  39, 250, 297, 262, 199,  14,  47,\n",
       "        94, 269, 227, 279, 201, 161,  43, 217, 145, 190, 105,  53,   1,\n",
       "        49,  80, 205,  34, 263,  91,  52, 264, 241,  13,  88, 166, 300,\n",
       "       134, 293, 243,  54,  50, 174, 189, 304, 187, 169,  58,  48, 235,\n",
       "       252,  21, 160, 276, 191, 257, 149, 130, 151,  99,  87, 214, 121,\n",
       "       305,  20, 188,  71, 106, 270, 102])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.stack([X_1,X_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_X_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-198f1291d718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m####Train test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_upper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_X_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_upper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_upper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fake_X_data' is not defined"
     ]
    }
   ],
   "source": [
    "####Train test split\n",
    "train_upper = int(np.around((X_1.shape[0]*0.9),0))\n",
    "\n",
    "X_train = X[:train_upper]\n",
    "X_test = X[train_upper:]\n",
    "\n",
    "Y_train = Y[:train_upper]\n",
    "Y_test = Y[train_upper:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train validation split\n",
    "train_upper = int(np.around((X_train.shape[0]*0.8),0))\n",
    "X_train = X_train[:train_upper]\n",
    "X_val = X_train[train_upper:]\n",
    "\n",
    "Y_train = Y_train[:train_upper]\n",
    "Y_val = Y_train[train_upper:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (X_train, Y_train)\n",
    "validation = (X_val, Y_val)\n",
    "test = (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN():\n",
    "    model = Sequential(name='CNN')\n",
    "    \n",
    "    # elu=Exponential Linear Unit, similar to leaky Relu\n",
    "    #perhaps normalise in layer 1 \n",
    "    \n",
    "    # Convolution Layers\n",
    "    model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2],X_train.shape[3])))\n",
    "    model.add(MaxPooling2D(2))\n",
    "    model.add(Conv2D(32, (2, 2), strides=(1, 1), activation='elu'))\n",
    "    model.add(MaxPooling2D(2))\n",
    "    model.add(Conv2D(64, (2, 2), strides=(1, 1), activation='elu'))\n",
    "    model.add(MaxPooling2D(2))\n",
    "    model.add(Conv2D(128, (2, 2), strides=(1, 1), activation='elu'))\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.1))\n",
    "    #change to sigmoid if pic50 between 0 and 1\n",
    "    model.add(Dense(2,activation = 'linear'))\n",
    "    \n",
    "     \n",
    "    optimizer = Adam(learning_rate=1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_CNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train \n",
    "##monitor early stopping using val_acc\n",
    "#Set min_delta to 1e-3\n",
    "monitor = EarlyStopping(monitor='val_loss',\n",
    "                        min_delta=0,\n",
    "                        patience=15,\n",
    "                        verbose=1, \n",
    "                        mode='auto',\n",
    "                        restore_best_weights=True)\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=64,\n",
    "          epochs=200, \n",
    "          validation_data=(X_val, Y_val),\n",
    "          callbacks=[monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test model w/ best weights on validation data\n",
    "model_loss = model.evaluate(X_test,y_test_s)\n",
    "print(f\"Model loss:{model_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
