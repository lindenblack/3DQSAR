{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "model_code_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZIZYU8sT11R",
        "outputId": "06fa053f-d70a-4a8f-82fe-f08ceea0f0aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Github/3DQSAR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Github/3DQSAR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO1PbjDlUNuH"
      },
      "source": [
        "# !pip install --upgrade batchgenerators"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbzLAnR4TqxL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import BatchNormalization,Flatten,\\\n",
        "Add,Input,Dense, Dropout, Activation, InputLayer, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# from augmentation_code import data_augmentation\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import os \n",
        "import pickle\n",
        "import scipy\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPNVpJMKVBRh"
      },
      "source": [
        "X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/data.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swgSOOwfn2wP"
      },
      "source": [
        "new_X = scipy.ndimage.rotate(X_1[0],90,reshape=False,order=3)\n",
        "#random.choice([90,180,270])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHt3wsRdoaBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2820771-cca5-46e8-a17e-30180ad2a19d"
      },
      "source": [
        "mol5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([44044, 44045, 44046, ..., 45042, 45043, 45044]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD0wk7eyn9Rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0e17c8-2120-4b33-b28e-8b511bd16828"
      },
      "source": [
        "Y[44044]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeP7Lf-bn9cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28a9f19-8d70-470e-c3be-55c58cf22cf4"
      },
      "source": [
        "np.linspace(Y.min(),Y.max(),10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.043351  , 5.44964533, 5.85593967, 6.262234  , 6.66852833,\n",
              "       7.07482267, 7.481117  , 7.88741133, 8.29370567, 8.7       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVl_IwAAzBn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fc1653-d3a1-4f62-bada-6485f546a22f"
      },
      "source": [
        "np.sort(Y[::1001])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.043351, 5.154902, 5.19382 , 5.199971, 5.2     , 5.200659,\n",
              "       5.250264, 5.260428, 5.30103 , 5.318759, 5.337242, 5.387216,\n",
              "       5.39    , 5.497573, 5.58838 , 5.59998 , 5.657577, 5.699622,\n",
              "       5.72    , 5.769551, 5.815309, 5.853872, 5.886057, 5.9     ,\n",
              "       6.008774, 6.091515, 6.102373, 6.195861, 6.200659, 6.32    ,\n",
              "       6.346787, 6.37    , 6.400117, 6.413413, 6.42    , 6.537602,\n",
              "       6.542118, 6.548214, 6.55    , 6.55752 , 6.63    , 6.69897 ,\n",
              "       6.886057, 7.      , 7.      , 7.      , 7.1     , 7.28    ,\n",
              "       7.809668, 7.85    , 7.9     , 8.      , 8.102373, 8.7     ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTMqCZxq9Qsj"
      },
      "source": [
        "5.19382,5.497573,5.699622,5.9,6.346787,6.102373,6.63,7.,7.9,8."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsgCYtKHA0Kg",
        "outputId": "c1da23cf-55f5-4289-ada9-d9cd14f82140"
      },
      "source": [
        "X_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54054, 14, 14, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_kgPQQPAnkd"
      },
      "source": [
        "z=np.squeeze(test_index).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41SgX7zBxIoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812e7f50-0610-44a8-eefc-25e5087f1850"
      },
      "source": [
        "np.delete(X_1,z,0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54053, 14, 14, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iJVQ-qlTqxR"
      },
      "source": [
        "# X_1, X_2, Y = import_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFNVjhdfTqxS"
      },
      "source": [
        "####Augment and extend data\n",
        "# X_1_train, X_2_train, Y_train = data_augmentation(X_1_train,X_2_train,Y_train,augment_repetitions=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WifeSIQgTqxU"
      },
      "source": [
        "###Pickle data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CALiUs2ATqxV"
      },
      "source": [
        "###Normalise image data \n",
        "###Normalise by amax value?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DykRKOZikxEF"
      },
      "source": [
        "def split_shuffle(X_1,X_2,Y,augment,aug_iter):\n",
        "    ###Reshape\n",
        "    X_1 = np.reshape(X_1,(X_1.shape[0],X_1.shape[1],X_1.shape[2],X_1.shape[3],1))\n",
        "    X_2 = np.reshape(X_2,(X_2.shape[0],X_2.shape[1],X_2.shape[2],X_2.shape[3],1))\n",
        "    \n",
        "    mol1 = np.where(Y==(5.154902))\n",
        "    mol2 = np.where(Y==(5.815309))\n",
        "    mol3 = np.where(Y==(6.69897))\n",
        "    mol4 = np.where(Y==(7.85))\n",
        "    mol5 = np.where(Y==(8.102373)) \n",
        "\n",
        "    test_index = np.hstack([mol1,mol2,mol3,mol4,mol5])\n",
        "\n",
        "    test_index = np.squeeze(test_index)\n",
        "\n",
        "    X_1_train = np.delete(X_1,test_index,0)\n",
        "    X_2_train = np.delete(X_2,test_index,0)\n",
        "    X_1_test = X_1[test_index]\n",
        "    X_2_test = X_2[test_index]\n",
        "\n",
        "    Y_train = np.delete(Y,test_index)\n",
        "    Y_test = Y[test_index]\n",
        "\n",
        "           \n",
        "    mol1 = np.where(Y_train==(5.19382))\n",
        "    mol2 = np.where(Y_train==(5.497573))\n",
        "    mol3 = np.where(Y_train==(5.699622))\n",
        "    mol4 = np.where(Y_train==(5.9))\n",
        "    mol5 = np.where(Y_train==(6.346787))\n",
        "\n",
        "    mol6 = np.where(Y_train==(6.102373))\n",
        "    mol7 = np.where(Y_train==(6.63))\n",
        "    mol8 = np.where(Y_train==(7.1))\n",
        "    mol9 = np.where(Y_train==(7.9))\n",
        "    mol10 = np.where(Y_train==(8.)) \n",
        "    \n",
        "    val_index = np.hstack([mol1,mol2,mol3,mol4,mol5,\n",
        "                           mol6,mol7,mol8,mol9,mol10])\n",
        "    \n",
        "    val_index = np.squeeze(val_index)\n",
        "  \n",
        "    X_1_val = X_1_train[val_index]\n",
        "    X_2_val = X_2_train[val_index]\n",
        "    X_1_train = np.delete(X_1_train, val_index, 0)\n",
        "    X_2_train = np.delete(X_2_train, val_index, 0)\n",
        "\n",
        "    Y_val = Y_train[val_index]\n",
        "    Y_train = np.delete(Y_train, val_index)\n",
        "\n",
        "    \n",
        "    permutation_train = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_train.shape[0])\n",
        "    permutation_test = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_test.shape[0])\n",
        "    permutation_val = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_val.shape[0])\n",
        "\n",
        "    split_train = int(np.around(X_1_train.shape[0]/4,0))\n",
        "    split_val = int(np.around(X_1_val.shape[0]/4,0))\n",
        "    split_test = int(np.around(X_1_test.shape[0]/4,0))\n",
        "\n",
        "    X_1_val =   X_1_val[permutation_val]#[:split_val] \n",
        "    X_2_val =   X_2_val[permutation_val]#[:split_val] \n",
        "    X_1_train = X_1_train[permutation_train]#[:split_train]\n",
        "    X_2_train = X_2_train[permutation_train]#[:split_train]\n",
        "    Y_val =     Y_val[permutation_val]#[:split_val]\n",
        "    Y_train =   Y_train[permutation_train]#[:split_train] \n",
        "    X_1_test =  X_1_test[permutation_test]#[:split_test]\n",
        "    X_2_test =  X_2_test[permutation_test]#[:split_test]\n",
        "    Y_test =    Y_test[permutation_test]#[:split_test]\n",
        "   \n",
        "\n",
        "\n",
        "    if augment and aug_iter!=0:\n",
        "      indexes = np.where(Y_train>7.25)\n",
        "      for _ in np.arange(aug_iter):\n",
        "        \n",
        "        # new_X = scipy.ndimage.gaussian_filter(X_1_train[indexes],sigma=(_+1))\n",
        "        # X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "        # new_X = scipy.ndimage.gaussian_filter(X_2_train[indexes],sigma=(_+1))\n",
        "        # X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "        # Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "\n",
        "        new_X = scipy.ndimage.rotate(X_1_train[indexes],random.choice([90,180,270]),reshape=False,order=3)\n",
        "        X_1_train = np.concatenate([X_1_train,new_X])\n",
        "\n",
        "        new_X = scipy.ndimage.rotate(X_2_train[indexes],random.choice([90,180,270]),reshape=False,order=3)\n",
        "        X_2_train = np.concatenate([X_2_train,new_X])\n",
        "\n",
        "        Y_train = np.concatenate([Y_train,Y_train[indexes]])\n",
        "    else:\n",
        "      print(\"No augmentation!\")  \n",
        "\n",
        "    return X_1_train, X_1_test, X_1_val, X_2_train, X_2_test, X_2_val, Y_train, Y_test, Y_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDAg1E3JTqxa"
      },
      "source": [
        "def build_CNN(X_1_train,layer):\n",
        "    model = Sequential(name='CNN')\n",
        "    \n",
        "    # elu=Exponential Linear Unit, similar to leaky Relu\n",
        "    #perhaps normalise in layer 1 \n",
        "    \n",
        "    # Convolution Layers\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    inputs = Input(shape=(X_1_train.shape[1], X_1_train.shape[2],X_1_train.shape[3],X_1_train.shape[4]))\n",
        "    model=inputs\n",
        "    model=BatchNormalization()(model)\n",
        "    model = Conv3D(32, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    # model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    # model=BatchNormalization()(model)\n",
        "    model = Conv3D(64, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    model = MaxPooling3D(pool_size=(2,2,2))(model)\n",
        "    model = Conv3D(128, (2, 2, 2), strides=(1, 1, 1), activation='relu')(model)\n",
        "    # model = MaxPooling3D(pool_size=(1,1,1))(model)\n",
        "    # model=BatchNormalization()(model)\n",
        "    model = Flatten()(model)\n",
        "    ####increase\n",
        "    model = Dense(100,activation='relu')(model)\n",
        "    output = model\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxU1ILcJTqxa"
      },
      "source": [
        "def two_headed_network(X_1_train,layer):\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    X_1_CNN = build_CNN(X_1_train,layer)\n",
        "    X_2_CNN = build_CNN(X_1_train,layer)\n",
        "    network = Concatenate()([X_1_CNN.output,X_2_CNN.output])\n",
        "    network = Add()([X_1_CNN.output,X_2_CNN.output])\n",
        "    # if layer==\"add\":\n",
        "    #   network = Add()([X_1_CNN.output,X_2_CNN.output])\n",
        "    #   print(layer)\n",
        "    # elif layer==\"concat\":\n",
        "    #   network = Concatenate()([X_1_CNN.output,X_2_CNN.output])\n",
        "    #   print(layer)\n",
        "    \n",
        "    network = Flatten()(network)\n",
        "    network = Dense(100,activation='relu')(network)\n",
        "    network = Dense(50,activation='relu')(network)\n",
        "    network = Dense(10,activation='relu')(network)\n",
        "    network = Dense(1,activation = 'linear')(network)\n",
        "    model = Model([X_1_CNN.input, X_2_CNN.input], network)\n",
        "    optimizer = Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    \n",
        "    return model  \n",
        "# CNN = two_headed_network(X_1_train,None)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY-3TNPivy-Q"
      },
      "source": [
        "CNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVRiKfqJG3v"
      },
      "source": [
        "tf.keras.utils.plot_model(CNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FolKD5zlAZSj"
      },
      "source": [
        "# #####Cross validation\n",
        "def train_CV(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "  X_2_val, Y_train, Y_val):\n",
        "  perm = np.random.RandomState(seed=42)\\\n",
        "                  .permutation(X_1_train.shape[0])\n",
        "  num_folds=4\n",
        "  kfold = KFold(n_splits=num_folds, shuffle=False, random_state=42)\n",
        "  monitor = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=7,\n",
        "                          verbose=1, \n",
        "                          mode='auto',\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "  for perms_train,perms_test in kfold.split(X=perm,y=perm):\n",
        "      CNN.fit([X_1_train[perms_train], X_2_train[perms_train]],\n",
        "                        Y_train[perms_train],\n",
        "                        batch_size=32,\n",
        "                        epochs=1000,\n",
        "                        verbose=0, \n",
        "                        validation_data=([X_1_train[perms_test], X_2_train[perms_test]],\n",
        "                                          Y_train[perms_test]),\n",
        "                                          callbacks=[monitor])\n",
        "  model_loss = CNN.evaluate([X_1_val,X_2_val], Y_val)\n",
        "  return model_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdo3DyR_BwAo"
      },
      "source": [
        "##Train \n",
        "##monitor early stopping using val_acc\n",
        "#Set min_delta to 1e-3\n",
        "def train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "  X_2_val, Y_train, Y_val, batch):\n",
        "\n",
        "  monitor = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=15,\n",
        "                          verbose=1, \n",
        "                          mode='auto',\n",
        "                          restore_best_weights=True)\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "  CNN.fit([X_1_train, X_2_train],\n",
        "          Y_train,\n",
        "          batch_size=batch,\n",
        "          epochs=1000, \n",
        "          validation_data=([X_1_val, X_2_val],\n",
        "                            Y_val),\n",
        "                            callbacks=[monitor],\n",
        "          shuffle=False,\n",
        "          verbose=1)\n",
        "  \n",
        "  model_loss = CNN.evaluate([X_1_val,X_2_val], Y_val, verbose=0)\n",
        "  return model_loss\n",
        "#######################################\n",
        "#Reset shuffle to True\n",
        "#######################################"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLBgFURvQPzo"
      },
      "source": [
        "def experiment(itr,layer):\n",
        "  X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/data.p\", \"rb\"))\n",
        "\n",
        "  X_1_train, X_1_test, X_1_val, X_2_train, X_2_test,\\\n",
        "  X_2_val, Y_train, Y_test, Y_val = split_shuffle(X_1,X_2,Y,augment=False,aug_iter=itr)\n",
        "  del X_1,X_2,Y\n",
        "  \n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "\n",
        "  CNN = two_headed_network(X_1_train,layer)\n",
        "  print(X_1_train.shape)\n",
        "  # if CV:\n",
        "  #   loss = train_CV(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "  #                   X_2_val, Y_train, Y_val)\n",
        "  batch=32\n",
        "  loss = train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "                 X_2_val, Y_train, Y_val, batch)\n",
        "  print(loss)\n",
        "  plt.hist(Y_train)\n",
        "  return loss,CNN\n",
        "  \n",
        "  #1 iter = best"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1nkIs8G_NFw"
      },
      "source": [
        "##################Run experiment\n",
        "\n",
        "\n",
        "losses=[]\n",
        "layer=None\n",
        "# for layer in [\"\",\"no\"]:\n",
        "for batch in [16,32,64,128]:\n",
        "  itr_loss=0\n",
        "  for _ in np.arange(3):\n",
        "    loss,CNN = experiment(0,layer)\n",
        "    itr_loss+=loss\n",
        "    tf.keras.backend.clear_session()\n",
        "  print(itr_loss/3)\n",
        "  losses.append(itr_loss/5)\n",
        "# with (open(\"results_conv_fc_concat.txt\",\"w\")) as file:\n",
        "#   file.write(f\"add{str(losses[0])}\")\n",
        "#   file.write(\"\\n\")\n",
        "#   file.write(f\"concat{str(losses[1])}\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L97qyUfeMfcp",
        "outputId": "b5d8dabe-d310-4dd0-d879-6aaf6a7a3065"
      },
      "source": [
        "#################### Run single test\n",
        "\n",
        "\n",
        "layer=32\n",
        "loss,CNN = experiment(0,layer)\n",
        "itr_loss+=loss\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No augmentation!\n",
            "(39039, 14, 14, 14, 1)\n",
            "Epoch 1/1000\n",
            "1220/1220 [==============================] - 12s 9ms/step - loss: 0.8138 - val_loss: 1.3523\n",
            "Epoch 2/1000\n",
            "1220/1220 [==============================] - 11s 9ms/step - loss: 0.2214 - val_loss: 1.7980\n",
            "Epoch 3/1000\n",
            "1220/1220 [==============================] - 11s 9ms/step - loss: 0.1293 - val_loss: 1.7081\n",
            "Epoch 4/1000\n",
            "1220/1220 [==============================] - 11s 9ms/step - loss: 0.0717 - val_loss: 1.8399\n",
            "Epoch 5/1000\n",
            "1220/1220 [==============================] - 11s 9ms/step - loss: 0.0545 - val_loss: 1.8583\n",
            "Epoch 6/1000\n",
            " 765/1220 [=================>............] - ETA: 3s - loss: 0.0408"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7kvLPaPpBqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d0d18e-8a6b-4f6b-ac45-6981151679cf"
      },
      "source": [
        "CNN.predict([X_1_train,X_2_train])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.0280857],\n",
              "       [6.624783 ],\n",
              "       [6.4909406],\n",
              "       ...,\n",
              "       [5.956703 ],\n",
              "       [6.545893 ],\n",
              "       [6.244688 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMrBktnEqwlV"
      },
      "source": [
        "preds = CNN.predict([X_1_val,X_2_val])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX4haxNerxp9",
        "outputId": "d7cbe6e1-4e04-4b15-da16-42adaa60eae6"
      },
      "source": [
        "preds[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.0426764],\n",
              "       [5.2225046],\n",
              "       [5.326735 ],\n",
              "       [5.21741  ],\n",
              "       [6.7216215],\n",
              "       [5.3269157],\n",
              "       [7.0873995],\n",
              "       [6.986512 ],\n",
              "       [5.55239  ],\n",
              "       [7.1098957]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhyg722_rz7T",
        "outputId": "e1024621-632f-4252-83e6-3b143c64c918"
      },
      "source": [
        "Y_val[:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.1     , 8.      , 5.19382 , 8.      , 5.699622, 5.9     ,\n",
              "       7.1     , 5.497573, 5.497573, 7.1     ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIeh61n6pmhG",
        "outputId": "fb73a36c-3167-430e-c455-3a5883022a4a"
      },
      "source": [
        "X_1_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39039, 14, 14, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_z-to8pWPl"
      },
      "source": [
        "X_1_val[permutation_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d018pZm-Hm36"
      },
      "source": [
        "    X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/data.p\", \"rb\"))\n",
        "  \n",
        "    \n",
        "    X_1 = np.reshape(X_1,(X_1.shape[0],X_1.shape[1],X_1.shape[2],X_1.shape[3],1))\n",
        "    X_2 = np.reshape(X_2,(X_2.shape[0],X_2.shape[1],X_2.shape[2],X_2.shape[3],1))\n",
        "    \n",
        "    mol1 = np.where(Y==(5.154902))\n",
        "    mol2 = np.where(Y==(5.815309))\n",
        "    mol3 = np.where(Y==(6.69897))\n",
        "    mol4 = np.where(Y==(7.85))\n",
        "    mol5 = np.where(Y==(8.102373)) \n",
        "\n",
        "    test_index = np.hstack([mol1,mol2,mol3,mol4,mol5])\n",
        "\n",
        "    test_index = np.squeeze(test_index)\n",
        "\n",
        "    X_1_train = np.delete(X_1,test_index,0)\n",
        "    X_2_train = np.delete(X_2,test_index,0)\n",
        "    X_1_test = X_1[test_index]\n",
        "    X_2_test = X_2[test_index]\n",
        "\n",
        "    Y_train = np.delete(Y,test_index)\n",
        "    Y_test = Y[test_index]\n",
        "\n",
        "           \n",
        "    mol1 = np.where(Y_train==(5.19382))\n",
        "    mol2 = np.where(Y_train==(5.497573))\n",
        "    mol3 = np.where(Y_train==(5.699622))\n",
        "    mol4 = np.where(Y_train==(5.9))\n",
        "    mol5 = np.where(Y_train==(6.346787))\n",
        "\n",
        "    mol6 = np.where(Y_train==(6.102373))\n",
        "    mol7 = np.where(Y_train==(6.63))\n",
        "    mol8 = np.where(Y_train==(7.1))\n",
        "    mol9 = np.where(Y_train==(7.9))\n",
        "    mol10 = np.where(Y_train==(8.)) \n",
        "    \n",
        "    val_index = np.hstack([mol1,mol2,mol3,mol4,mol5,\n",
        "                           mol6,mol7,mol8,mol9,mol10])\n",
        "    \n",
        "    val_index = np.squeeze(val_index)\n",
        "\n",
        "    X_1_val = X_1_train[val_index]\n",
        "    X_2_val = X_2_train[val_index]\n",
        "    X_1_train = np.delete(X_1_train, val_index, 0)\n",
        "    X_2_train = np.delete(X_2_train, val_index, 0)\n",
        "\n",
        "    Y_val = Y_train[val_index]\n",
        "    Y_train = np.delete(Y_train, val_index)\n",
        "\n",
        "    \n",
        "    permutation_train = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_train.shape[0])\n",
        "    permutation_test = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_test.shape[0])\n",
        "    permutation_val = np.random.RandomState(seed=42)\\\n",
        "                       .permutation(X_1_val.shape[0])\n",
        "\n",
        "    split_train = int(np.around(X_1_train.shape[0]/4,0))\n",
        "    split_val = int(np.around(X_1_val.shape[0]/4,0))\n",
        "    split_test = int(np.around(X_1_test.shape[0]/4,0))\n",
        "\n",
        "    X_1_val =   X_1_val[permutation_val]#[:split_val] \n",
        "    X_2_val =   X_2_val[permutation_val]#[:split_val] \n",
        "    X_1_train = X_1_train[permutation_train]#[:split_train]\n",
        "    X_2_train = X_2_train[permutation_train]#[:split_train]\n",
        "    Y_val =     Y_val[permutation_val]#[:split_val]\n",
        "    Y_train =   Y_train[permutation_train]#[:split_train] \n",
        "    X_1_test =  X_1_test[permutation_test]#[:split_test]\n",
        "    X_2_test =  X_2_test[permutation_test]#[:split_test]\n",
        "    Y_test =    Y_test[permutation_test]#[:split_test]\n",
        "   "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP8a0K9Mxzlp",
        "outputId": "59d0cf3b-b0e3-41b7-ce53-229df0b7a91f"
      },
      "source": [
        "[1.4205801904201507, 0.6195118814706803]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4205801904201507, 0.6195118814706803]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPEyt2zr-skB"
      },
      "source": [
        "param_dict= {\"batch_norm\":(True,False),\n",
        "             \"dropout\":(0.2,0.15,0.1),\n",
        "             \"l1\":(0.001,0.01,0.02),\n",
        "             \"l2\":(0.001,0.01,0.02),\n",
        "             \"l1_l2\":(0.001,0.01,0.02),\n",
        "             \"lr\":(1e-3,2e-3,1.5e-3),\n",
        "             \"batch_size\":(16,32,64,128),\n",
        "             \"acivation\":(\"relu\",\"elu\",\"\")\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktyYw6Z6Tqxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e78f59-b955-4edb-e52e-4ee0a7def66e"
      },
      "source": [
        " ##Test model w/ best weights on validation data\n",
        "model_loss = CNN.evaluate([X_1_val,X_2_val], Y_val)\n",
        "print(f\"Model loss:{model_loss}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "305/305 [==============================] - 1s 3ms/step - loss: 0.1351\n",
            "Model loss:0.13511130213737488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td75TZgfTr3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9c3451-4309-4eaa-e4f5-5eb73f85134f"
      },
      "source": [
        "X_1,X_2,Y = pickle.load(open(\"/content/drive/My Drive/Github/data.p\", \"rb\"))\n",
        "\n",
        "X_1_train, X_1_test, X_1_val, X_2_train, X_2_test,\\\n",
        "X_2_val, Y_train, Y_test, Y_val = split_shuffle(X_1,X_2,Y,augment=False,aug_iter=0)\n",
        "# del X_1,X_2,Y\n",
        "\n",
        "CNN = two_headed_network(X_1_train)\n",
        "print(X_1_train.shape)\n",
        "loss = train(CNN,X_1_train, X_1_val, X_2_train,\\\n",
        "X_2_val, Y_train, Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No augmentation!\n",
            "(38919, 14, 14, 14, 1)\n",
            "305/305 [==============================] - 1s 3ms/step - loss: 1.0267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQj6P4TrrU8n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}